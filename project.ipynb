{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlzAoCTQ4C2A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import fitz # PyMuPDF\n",
        "import io\n",
        "import cv2\n",
        "import pytesseract\n",
        "import json\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "\n",
        "def extract_block_diagrams_with_titles(pdf_path, output_folder, search_title, search_component):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    fig_pattern = re.compile(r'Fig \\d+\\.\\d+.*')\n",
        "    data = []\n",
        "\n",
        "    for page_number in range(len(pdf_document)):\n",
        "        page = pdf_document[page_number]\n",
        "        image_list = page.get_images(full=True)\n",
        "        images = []\n",
        "        titles = []\n",
        "\n",
        "        # Extract images from the page\n",
        "        for img_index, img in enumerate(image_list):\n",
        "            xref = img[0]\n",
        "            base_image = pdf_document.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            images.append(image)\n",
        "\n",
        "        # Extract text and match figure titles\n",
        "        text = page.get_text(\"text\")\n",
        "        for match in fig_pattern.finditer(text):\n",
        "            title = match.group().strip()\n",
        "            titles.append(title)\n",
        "\n",
        "        # Combine images and titles\n",
        "        for i, (image, title) in enumerate(zip(images, titles)):\n",
        "            # Perform OCR on the image with detailed output\n",
        "            ocr_data = pytesseract.image_to_data(cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR), output_type=pytesseract.Output.DICT)\n",
        "            elements = []\n",
        "            current_element = \"\"\n",
        "            previous_bottom = -1\n",
        "            previous_top = -1\n",
        "            previous_left = -1\n",
        "            previous_right = -1\n",
        "\n",
        "            for j in range(len(ocr_data['text'])):\n",
        "                text = ocr_data['text'][j].strip()\n",
        "                if text:\n",
        "                    top = ocr_data['top'][j]\n",
        "                    left = ocr_data['left'][j]\n",
        "                    width = ocr_data['width'][j]\n",
        "                    height = ocr_data['height'][j]\n",
        "                    right = left + width\n",
        "                    bottom = top + height\n",
        "\n",
        "                    if current_element and (top > previous_bottom + 10 or left > previous_right + 50):\n",
        "                        elements.append(current_element.strip())\n",
        "                        current_element = text\n",
        "                    else:\n",
        "                        if current_element:\n",
        "                            current_element += ' '\n",
        "                        current_element += text\n",
        "\n",
        "                    previous_bottom = bottom\n",
        "                    previous_top = top\n",
        "                    previous_left = left\n",
        "                    previous_right = right\n",
        "\n",
        "            if current_element:\n",
        "                elements.append(current_element.strip())\n",
        "\n",
        "            data.append({\"title\": title, \"elements\": elements, \"image_index\": i, \"page_number\": page_number + 1})\n",
        "\n",
        "            title_without_fig = re.sub(r'Fig \\d+\\.\\d+\\.', '', title)\n",
        "\n",
        "            # Search for title and component\n",
        "            if search_title.lower() in title_without_fig.lower():\n",
        "                for element in elements:\n",
        "                    if search_component.lower() in element.lower():\n",
        "                        print(f\"Found component '{search_component}' in title '{search_title}' on page {page_number + 1}\")\n",
        "\n",
        "            # Add title to the image\n",
        "            new_image = Image.new('RGB', (image.width, image.height + 30), 'white')\n",
        "            new_image.paste(image, (0, 0))\n",
        "            draw = ImageDraw.Draw(new_image)\n",
        "            font = ImageFont.load_default()\n",
        "            draw.text((10, image.height), title, font=font, fill=\"black\")\n",
        "\n",
        "            # Save the new image\n",
        "            image_path = os.path.join(output_folder, f\"page_{page_number+1}_img_{i+1}.png\")\n",
        "            new_image.save(image_path)\n",
        "\n",
        "    # Save data to a JSON file\n",
        "    output_path = os.path.join(output_folder, \"titles_and_elements.json\")\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "    return data\n",
        "\n",
        "pdf_path = \"/Users/ramganeshkasturi/Desktop/now/data.pdf\"\n",
        "output_folder = \"/Users/ramganeshkasturi/Desktop/now/output\"\n",
        "search_title = input(\"Enter the title to search for: \")\n",
        "search_component = input(\"Enter the component to search for: \")\n",
        "data = extract_block_diagrams_with_titles(pdf_path, output_folder, search_title, search_component)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CjLtEQHpnv9"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -qU langchain Faiss-gpu tiktoken sentence-transformers\n",
        "!pip install -qU trl Py7zr auto-gptq optimum\n",
        "!pip install -q rank_bm25\n",
        "!pip install -q PyPdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvTmpfADrM_9"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pma-uZoUqYQ2"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.embeddings import CacheBackedEmbeddings,HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.retrievers import BM25Retriever,EnsembleRetriever\n",
        "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.cache import InMemoryCache\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import prompt\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain import PromptTemplate\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzI5TOGiqytV"
      },
      "outputs": [],
      "source": [
        "dir_loader = DirectoryLoader(\"/content/data\",\n",
        "                             glob=\"*.pdf\",\n",
        "                             loader_cls=PyPDFLoader)\n",
        "docs = dir_loader.load()\n",
        "#\n",
        "print(f\"len of documents in :{len(docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbL4MihXq6Kc"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=200,)\n",
        "esops_documents = text_splitter.transform_documents(docs)\n",
        "print(f\"number of chunks in barbie documents : {len(esops_documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IqpV2-urc28"
      },
      "outputs": [],
      "source": [
        "store = LocalFileStore(\"./cache/\")\n",
        "embed_model_id = 'BAAI/bge-small-en-v1.5'\n",
        "core_embeddings_model = HuggingFaceEmbeddings(model_name=embed_model_id)\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(core_embeddings_model,\n",
        "                                                  store,\n",
        "                                                  namespace=embed_model_id)\n",
        "# Create VectorStore\n",
        "vectorstore = FAISS.from_documents(esops_documents,embedder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW8oRBLirlA1"
      },
      "outputs": [],
      "source": [
        "bm25_retriever = BM25Retriever.from_documents(esops_documents)\n",
        "bm25_retriever.k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiU4pa07rsB8"
      },
      "outputs": [],
      "source": [
        "query = \"what is a computer?\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "print(len(embedding_vector))\n",
        "#\n",
        "docs_resp = vectorstore.similarity_search_by_vector(embedding_vector,k=5)\n",
        "#\n",
        "for page in docs_resp:\n",
        "  print(page.page_content)\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7eR1hEXr0fX"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 1 -r 1\n",
        "query = \"what is a computer?\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs_resp = vectorstore.similarity_search_by_vector(embedding_vector,k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZAPjIeAr76U"
      },
      "outputs": [],
      "source": [
        "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\":5})\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever,faiss_retriever],\n",
        "                                       weights=[0.5,0.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVIlpA_gr_qc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n",
        "# To use a different branch, change revision\n",
        "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=False,\n",
        "                                             revision=\"gptq-8bit-32g-actorder_True\")\n",
        "#\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IkSZv8QsDpE"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "    top_p=0.95,\n",
        "    top_k=40,\n",
        "    repetition_penalty=1.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPRIX5LLsuUW"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1kmSN3fswK6"
      },
      "outputs": [],
      "source": [
        "langchain.llm_cache = InMemoryCache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6neTNQzs6AM"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE = '''\n",
        "You are my tech advisor. You are great at providing tips on computer hardware, software, and general technology with your knowledge in computer science.\n",
        "With the information being provided, try to answer the question.\n",
        "If you can't answer the question based on the information, either say you can't find an answer or unable to find an answer.\n",
        "So try to understand in depth about the context and answer only based on the information provided. Don't generate irrelevant answers.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Do provide only helpful answers\n",
        "\n",
        "Helpful answer:\n",
        "'''\n",
        "\n",
        "input_variables = ['context', 'question']\n",
        "\n",
        "custom_prompt = PromptTemplate(template=PROMPT_TEMPLATE,\n",
        "                            input_variables=input_variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5EmrfFatXRL"
      },
      "outputs": [],
      "source": [
        "handler = StdOutCallbackHandler()\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\":5}),\n",
        "    verbose=True,\n",
        "    callbacks=[handler],\n",
        "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KsylQomztiIq"
      },
      "outputs": [],
      "source": [
        "query = \"what is a computer?\"\n",
        "response = qa_with_sources_chain({\"query\":query})\n",
        "print(f\"Response generated : \\n {response['result']}\")\n",
        "print(f\"Source Documents : \\n {response['source_documents']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kILry8FJurWR"
      },
      "outputs": [],
      "source": [
        "handler = StdOutCallbackHandler()\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = ensemble_retriever,\n",
        "    callbacks=[handler],\n",
        "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rKjlFz1Kvba6"
      },
      "outputs": [],
      "source": [
        "query = \" \"\n",
        "response = qa_with_sources_chain({\"query\":query})\n",
        "print(f\"Response generated : \\n {response['result']}\")\n",
        "print(f\"Source Documents : \\n {response['source_documents']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFLikjcQwF49"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
